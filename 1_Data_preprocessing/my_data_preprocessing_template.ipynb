{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a template for data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ============ import the data set =========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 nan]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' nan 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n",
      "y: ['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('Data.csv', header = 0, sep = ',') #header=0:\n",
    "    #the first row in the data set, if header=1, then the\n",
    "    #second row is treated as the header, and lines >2 is \n",
    "    #the data, so the first row is neglected. header =\n",
    "    #None: no header row in the data.\n",
    "#dataset = pd.read_csv('https://s3-eu-west-1.amazonaws.com/shanebucket/downloads/uk-500.csv')\n",
    "#print('# of rows: %d, # of columns: %d \\n'\n",
    "#      %(dataset.shape[0], dataset.shape[1]))\n",
    "#\n",
    "#dataset.head(2)\n",
    "#dataset.tail(5)\n",
    "#dataset.iloc[0] #the first row\n",
    "#dataset.iloc[-4]\n",
    "#dataset.iloc[0, 3] #cell identified by row and column\n",
    "#dataset.iloc[:, -2] #the last second column\n",
    "#dataset.iloc[1, 1:3]\n",
    "#dataset.iloc[1, :-1]\n",
    "\n",
    "x = dataset.iloc[:, :3].values #values: transfrom from\n",
    "                #data frame to numpy array.\n",
    "y = dataset.iloc[:, -1].values\n",
    "print ('x: ', end = '') \n",
    "print(x)\n",
    "\n",
    "print ('y: ', end = '') \n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ========= Taking care of the missing data ======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: \n",
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 63777.77777777778]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' 38.77777777777778 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)#take the mean along axis = 0 (column)           \n",
    "#imputer = imputer.fit(x[:, 1:3])\n",
    "#xx = imputer.transform(x[:, 1:3])\n",
    "x[:, 1:3] = imputer.fit_transform(x[:, 1:3])\n",
    "\n",
    "print ('x: ')\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ========== Taking care of the categorical data ========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Independent categorical data: \n",
      "\n",
      "Before dealing with the dummy variable trap: \n",
      "x: \n",
      "[[1.00000000e+00 0.00000000e+00 0.00000000e+00 4.40000000e+01\n",
      "  7.20000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 2.70000000e+01\n",
      "  4.80000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 3.00000000e+01\n",
      "  5.40000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 3.80000000e+01\n",
      "  6.10000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 4.00000000e+01\n",
      "  6.37777778e+04]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 3.50000000e+01\n",
      "  5.80000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 3.87777778e+01\n",
      "  5.20000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 4.80000000e+01\n",
      "  7.90000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 5.00000000e+01\n",
      "  8.30000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 3.70000000e+01\n",
      "  6.70000000e+04]]\n",
      "After dealing with the dummy variable trap: \n",
      "x: \n",
      "[[0.00000000e+00 0.00000000e+00 4.40000000e+01 7.20000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 2.70000000e+01 4.80000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 3.00000000e+01 5.40000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 3.80000000e+01 6.10000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 4.00000000e+01 6.37777778e+04]\n",
      " [0.00000000e+00 0.00000000e+00 3.50000000e+01 5.80000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 3.87777778e+01 5.20000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 4.80000000e+01 7.90000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 5.00000000e+01 8.30000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 3.70000000e+01 6.70000000e+04]]\n",
      "\n",
      "===Dependent categorical data: \n",
      "\n",
      "y: \n",
      "[0 1 0 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,\\\n",
    "OneHotEncoder\n",
    "\n",
    "#Dealing with the independent categorical data\n",
    "print ('===Independent categorical data: \\n')\n",
    "label_encoder_x = LabelEncoder()\n",
    "x[:, 0] = label_encoder_x.fit_transform(x[:, 0])\n",
    "#x[:, 3] = label_encoder_x.fit_transform(x[:, 3])\n",
    "one_hot_encoder_x = OneHotEncoder(categorical_features = [0])\n",
    "x = one_hot_encoder_x.fit_transform(x).toarray() #x must\n",
    "                                   #be multi-dim array\n",
    "print ('Before dealing with the dummy variable trap: \\nx: ')\n",
    "print (x)\n",
    "x = x[:, 1:] #deal with the dummy variable trap.\n",
    "print ('After dealing with the dummy variable trap: \\nx: ')\n",
    "print (x)\n",
    "\n",
    "#Dealing with the categorical dependent variable. It can \n",
    "#be the same as the independent categorical variables, but \n",
    "#if it is binary (0/1, or yes/no, etc.), we can just use \n",
    "#LabelEncoder\n",
    "print ('\\n===Dependent categorical data: \\n')\n",
    "label_encoder_y = LabelEncoder()\n",
    "y = label_encoder_y.fit_transform(y)\n",
    "print ('y: ')\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ============ Feature scaling =========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature-scaled x: \n",
      "[[-6.54653671e-01 -6.54653671e-01  7.58874362e-01  7.49473254e-01]\n",
      " [-6.54653671e-01  1.52752523e+00 -1.71150388e+00 -1.43817841e+00]\n",
      " [ 1.52752523e+00 -6.54653671e-01 -1.27555478e+00 -8.91265492e-01]\n",
      " [-6.54653671e-01  1.52752523e+00 -1.13023841e-01 -2.53200424e-01]\n",
      " [ 1.52752523e+00 -6.54653671e-01  1.77608893e-01  6.63219199e-16]\n",
      " [-6.54653671e-01 -6.54653671e-01 -5.48972942e-01 -5.26656882e-01]\n",
      " [-6.54653671e-01  1.52752523e+00  0.00000000e+00 -1.07356980e+00]\n",
      " [-6.54653671e-01 -6.54653671e-01  1.34013983e+00  1.38753832e+00]\n",
      " [ 1.52752523e+00 -6.54653671e-01  1.63077256e+00  1.75214693e+00]\n",
      " [-6.54653671e-01 -6.54653671e-01 -2.58340208e-01  2.93712492e-01]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler() #or normalization function\n",
    "x = sc.fit_transform(x)\n",
    "#if y is not needed for feature scaling, then don't \n",
    "#y = sc.fit_transform(y)\n",
    "#y = sc.fit_transform(y.reshape(-1, 1)) #if only one\n",
    "                        #feature\n",
    "print ('The feature-scaled x: ')\n",
    "print (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ============ Splitting data into training and testing set  ========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: \n",
      "[[ 1.52752523e+00 -6.54653671e-01  1.77608893e-01  6.63219199e-16]\n",
      " [-6.54653671e-01 -6.54653671e-01 -2.58340208e-01  2.93712492e-01]\n",
      " [-6.54653671e-01  1.52752523e+00 -1.71150388e+00 -1.43817841e+00]\n",
      " [-6.54653671e-01  1.52752523e+00  0.00000000e+00 -1.07356980e+00]\n",
      " [-6.54653671e-01 -6.54653671e-01  1.34013983e+00  1.38753832e+00]\n",
      " [-6.54653671e-01  1.52752523e+00 -1.13023841e-01 -2.53200424e-01]\n",
      " [-6.54653671e-01 -6.54653671e-01  7.58874362e-01  7.49473254e-01]\n",
      " [-6.54653671e-01 -6.54653671e-01 -5.48972942e-01 -5.26656882e-01]]\n",
      "y_train: \n",
      "[1 1 1 0 1 0 0 1]\n",
      "x_test: \n",
      "[[ 1.52752523 -0.65465367 -1.27555478 -0.89126549]\n",
      " [ 1.52752523 -0.65465367  1.63077256  1.75214693]]\n",
      "y_test\n",
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=0)\n",
    "print ('x_train: ')\n",
    "print (x_train)\n",
    "print ('y_train: ')\n",
    "print (y_train)\n",
    "print ('x_test: ')\n",
    "print (x_test)\n",
    "print ('y_test')\n",
    "print (y_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
