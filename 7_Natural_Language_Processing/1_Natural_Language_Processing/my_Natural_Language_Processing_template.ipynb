{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ======= Import the data set ========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('Restaurant_Reviews.tsv', delimiter = '\\t', quoting = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ====== Cleaning the dataset ======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "corpus = []\n",
    "\n",
    "for i in range(dataset.shape[0]):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', dataset.iloc[i, 0]) #remove the non-letter characters.\n",
    "    review = review.lower()\n",
    "    review = review.split() #for dealing with each word in the next step\n",
    "    review = [PorterStemmer().stem(word) for word in review if not word in set(stopwords.words('english'))] #'set' is faster\n",
    "    review = ' '.join(review) #put into a string\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ====== Create the Bag of Words model ======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 1500) #top 1500 features ordered by frequency\n",
    "x = cv.fit_transform(corpus).toarray()\n",
    "y = dataset.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ======= Splitting the dataset ============"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ======= Utilize different classification models ======="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ======= Naive Bayes ======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The averaged accuracy is 0.673657, and\n",
      " std is 0.049905.\n",
      "\n",
      "The accuracy for the training set is 0.921250.\n",
      "\n",
      "The accuracy for the test set is 0.730000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred_train = classifier.predict(x_train)\n",
    "y_pred_test = classifier.predict(x_test)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 10)\n",
    "print ('The averaged accuracy is %f, and\\n std is %f.\\n'%(accuracies.mean(), accuracies.std()))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_train = confusion_matrix(y_train, y_pred_train, labels=[0, 1])\n",
    "cm_test = confusion_matrix(y_test, y_pred_test, labels=[0, 1]) #lables indicate the order of the results\n",
    "print ('The accuracy for the training set is %f.\\n'%((cm_train[0][0]+cm_train[1][1])/(x_train.shape[0])))\n",
    "print ('The accuracy for the test set is %f.\\n'%((cm_test[0][0]+cm_test[1][1])/(sum(sum(cm_test)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ======== Logistic Regression ======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The averaged accuracy is 0.774978, and\n",
      " std is 0.033634.\n",
      "\n",
      "The accuracy for the training set is 0.958750.\n",
      "\n",
      "The accuracy for the test set is 0.710000.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/LianshuiZhao/anaconda/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/LianshuiZhao/anaconda/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/LianshuiZhao/anaconda/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/LianshuiZhao/anaconda/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/LianshuiZhao/anaconda/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/LianshuiZhao/anaconda/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/LianshuiZhao/anaconda/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/LianshuiZhao/anaconda/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/LianshuiZhao/anaconda/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/LianshuiZhao/anaconda/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/LianshuiZhao/anaconda/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state=0)\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred_train = classifier.predict(x_train)\n",
    "y_pred_test = classifier.predict(x_test)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 10)\n",
    "print ('The averaged accuracy is %f, and\\n std is %f.\\n'%(accuracies.mean(), accuracies.std()))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_train = confusion_matrix(y_train, y_pred_train, labels=[0, 1])\n",
    "cm_test = confusion_matrix(y_test, y_pred_test, labels=[0, 1]) #lables indicate the order of the results\n",
    "print ('The accuracy for the training set is %f.\\n'%((cm_train[0][0]+cm_train[1][1])/(x_train.shape[0])))\n",
    "print ('The accuracy for the test set is %f.\\n'%((cm_test[0][0]+cm_test[1][1])/(sum(sum(cm_test)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ======== K Nearest Neighbors ======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The averaged accuracy is 0.662390, and\n",
      " std is 0.041453.\n",
      "\n",
      "The accuracy for the training set is 0.746250.\n",
      "\n",
      "The accuracy for the test set is 0.595000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=8, p=2)\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred_train = classifier.predict(x_train)\n",
    "y_pred_test = classifier.predict(x_test)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 10)\n",
    "print ('The averaged accuracy is %f, and\\n std is %f.\\n'%(accuracies.mean(), accuracies.std()))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_train = confusion_matrix(y_train, y_pred_train, labels=[0, 1])\n",
    "cm_test = confusion_matrix(y_test, y_pred_test, labels=[0, 1]) #lables indicate the order of the results\n",
    "print ('The accuracy for the training set is %f.\\n'%((cm_train[0][0]+cm_train[1][1])/(x_train.shape[0])))\n",
    "print ('The accuracy for the test set is %f.\\n'%((cm_test[0][0]+cm_test[1][1])/(sum(sum(cm_test)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ====== Linear SVM ======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The averaged accuracy is 0.762430, and\n",
      " std is 0.031449.\n",
      "\n",
      "The accuracy for the training set is 0.986250.\n",
      "\n",
      "The accuracy for the test set is 0.735000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel= 'linear', decision_function_shape = 'ovo', random_state= 0, C = 2)\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred_train = classifier.predict(x_train)\n",
    "y_pred_test = classifier.predict(x_test)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 10)\n",
    "print ('The averaged accuracy is %f, and\\n std is %f.\\n'%(accuracies.mean(), accuracies.std()))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_train = confusion_matrix(y_train, y_pred_train, labels=[0, 1])\n",
    "cm_test = confusion_matrix(y_test, y_pred_test, labels=[0, 1]) #lables indicate the order of the results\n",
    "print ('The accuracy for the training set is %f.\\n'%((cm_train[0][0]+cm_train[1][1])/(x_train.shape[0])))\n",
    "print ('The accuracy for the test set is %f.\\n'%((cm_test[0][0]+cm_test[1][1])/(sum(sum(cm_test)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ====== Kernel SVM ======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The averaged accuracy is 0.507486, and\n",
      " std is 0.007774.\n",
      "\n",
      "The accuracy for the training set is 0.511250.\n",
      "\n",
      "The accuracy for the test set is 0.495000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel= 'rbf', decision_function_shape = 'ovo', random_state= 0, C = 5, gamma = 'auto')\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred_train = classifier.predict(x_train)\n",
    "y_pred_test = classifier.predict(x_test)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 10)\n",
    "print ('The averaged accuracy is %f, and\\n std is %f.\\n'%(accuracies.mean(), accuracies.std()))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_train = confusion_matrix(y_train, y_pred_train, labels=[0, 1])\n",
    "cm_test = confusion_matrix(y_test, y_pred_test, labels=[0, 1]) #lables indicate the order of the results\n",
    "print ('The accuracy for the training set is %f.\\n'%((cm_train[0][0]+cm_train[1][1])/(x_train.shape[0])))\n",
    "print ('The accuracy for the test set is %f.\\n'%((cm_test[0][0]+cm_test[1][1])/(sum(sum(cm_test)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ====== Decision Tree ======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The averaged accuracy is 0.705036, and\n",
      " std is 0.045112.\n",
      "\n",
      "The accuracy for the training set is 0.996250.\n",
      "\n",
      "The accuracy for the test set is 0.710000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred_train = classifier.predict(x_train)\n",
    "y_pred_test = classifier.predict(x_test)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 10)\n",
    "print ('The averaged accuracy is %f, and\\n std is %f.\\n'%(accuracies.mean(), accuracies.std()))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_train = confusion_matrix(y_train, y_pred_train, labels=[0, 1])\n",
    "cm_test = confusion_matrix(y_test, y_pred_test, labels=[0, 1]) #lables indicate the order of the results\n",
    "print ('The accuracy for the training set is %f.\\n'%((cm_train[0][0]+cm_train[1][1])/(x_train.shape[0])))\n",
    "print ('The accuracy for the test set is %f.\\n'%((cm_test[0][0]+cm_test[1][1])/(sum(sum(cm_test)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ====== Random Forest ======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The averaged accuracy is 0.741272, and\n",
      " std is 0.023536.\n",
      "\n",
      "The accuracy for the training set is 0.996250.\n",
      "\n",
      "The accuracy for the test set is 0.740000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(criterion = 'gini', n_estimators = 35, random_state = 0)\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred_train = classifier.predict(x_train)\n",
    "y_pred_test = classifier.predict(x_test)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 10)\n",
    "print ('The averaged accuracy is %f, and\\n std is %f.\\n'%(accuracies.mean(), accuracies.std()))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_train = confusion_matrix(y_train, y_pred_train, labels=[0, 1])\n",
    "cm_test = confusion_matrix(y_test, y_pred_test, labels=[0, 1]) #lables indicate the order of the results\n",
    "print ('The accuracy for the training set is %f.\\n'%((cm_train[0][0]+cm_train[1][1])/(x_train.shape[0])))\n",
    "print ('The accuracy for the test set is %f.\\n'%((cm_test[0][0]+cm_test[1][1])/(sum(sum(cm_test)))))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
